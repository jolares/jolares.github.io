"use strict";(self.webpackChunkai_blog=self.webpackChunkai_blog||[]).push([[564],{876:(e,r,n)=>{n.d(r,{Zo:()=>f,kt:()=>g});var t=n(2784);function i(e,r,n){return r in e?Object.defineProperty(e,r,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[r]=n,e}function o(e,r){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);r&&(t=t.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),n.push.apply(n,t)}return n}function a(e){for(var r=1;r<arguments.length;r++){var n=null!=arguments[r]?arguments[r]:{};r%2?o(Object(n),!0).forEach((function(r){i(e,r,n[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(n,r))}))}return e}function c(e,r){if(null==e)return{};var n,t,i=function(e,r){if(null==e)return{};var n,t,i={},o=Object.keys(e);for(t=0;t<o.length;t++)n=o[t],r.indexOf(n)>=0||(i[n]=e[n]);return i}(e,r);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)n=o[t],r.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=t.createContext({}),s=function(e){var r=t.useContext(l),n=r;return e&&(n="function"==typeof e?e(r):a(a({},r),e)),n},f=function(e){var r=s(e.components);return t.createElement(l.Provider,{value:r},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var r=e.children;return t.createElement(t.Fragment,{},r)}},m=t.forwardRef((function(e,r){var n=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,f=c(e,["components","mdxType","originalType","parentName"]),p=s(n),m=i,g=p["".concat(l,".").concat(m)]||p[m]||u[m]||o;return n?t.createElement(g,a(a({ref:r},f),{},{components:n})):t.createElement(g,a({ref:r},f))}));function g(e,r){var n=arguments,i=r&&r.mdxType;if("string"==typeof e||i){var o=n.length,a=new Array(o);a[0]=m;var c={};for(var l in r)hasOwnProperty.call(r,l)&&(c[l]=r[l]);c.originalType=e,c[p]="string"==typeof e?e:i,a[1]=c;for(var s=2;s<o;s++)a[s]=n[s];return t.createElement.apply(null,a)}return t.createElement.apply(null,n)}m.displayName="MDXCreateElement"},2791:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>c,toc:()=>s});var t=n(7896),i=(n(7294),n(876));const o={sidebar_position:4},a="Inverse Reinforcement Learning (IRL)",c={unversionedId:"reinforcement-learning/inverse-reinforcement-learning",id:"reinforcement-learning/inverse-reinforcement-learning",title:"Inverse Reinforcement Learning (IRL)",description:"",source:"@site/docs/reinforcement-learning/inverse-reinforcement-learning.md",sourceDirName:"reinforcement-learning",slug:"/reinforcement-learning/inverse-reinforcement-learning",permalink:"/docs/reinforcement-learning/inverse-reinforcement-learning",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/reinforcement-learning/inverse-reinforcement-learning.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"docsSidebar",previous:{title:"Reinforcement Learning",permalink:"/docs/category/reinforcement-learning"},next:{title:"Policy-Iteration",permalink:"/docs/reinforcement-learning/policy-iteration"}},l={},s=[],f={toc:s},p="wrapper";function u(e){let{components:r,...n}=e;return(0,i.kt)(p,(0,t.Z)({},f,n,{components:r,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"inverse-reinforcement-learning-irl"},"Inverse Reinforcement Learning (IRL)"))}u.isMDXComponent=!0}}]);